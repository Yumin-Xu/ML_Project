Training this data set was generally quite easy. Due to the nature of the data set we used, the data for Defense of the Ancients 2 was already split into training and testing data sets. However, because this split did not represent the 80-20 proportions that we wanted to work with, we needed to re-combine these data sets and then re-split them after preprocessing. Preprocessing this data wasn't complex, as all that needed to be done was change the '-1' values to '0' values for the 'Win' category, and then convert the '0' and '1' values to 'FALSE' and 'TRUE' values, respectively. Additionally, all non-win categories were normalized to be within the range of 0 to 1.\\
After this setup, a random sample of roughly $80\%$ of all data points were selected to comprise the training set, while the remaining $20\%$ formed the testing set. The Naive Bayes model was then trained on this training set. This sampling and training process was performed 100 separate times in order to find a relatively high-quality model.